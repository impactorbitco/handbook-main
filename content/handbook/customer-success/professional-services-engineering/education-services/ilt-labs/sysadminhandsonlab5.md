---
title: "GitLab System Admin - Hands-On Lab: Logging and Monitoring GitLab Omnibus"
description: "This Hands-On Guide demonstrates how to monitor your GitLab Omnibus instance and analyze your logs"
---

> Estimated time to complete: 30 minutes

## Objectives

The objective of this lab is to demonstrate how to use Prometheus and Grafana for log analysis and monitoring.

## Task A. Access the Prometheus Service

1. GitLab's Prometheus server can be reached via TCP port 9090. Unfortunately, the training environment currently blocks inbound traffic to that port. As a workaround, you can open an SSH tunnel as follows.

    ```bash
    ssh -L 9090:localhost:9090 -i <SSH_KEY_NAME> student-user@<BASTION_SERVER_IP>
    ssh -L 9090:localhost:9090 -i ~/.ssh/ilt_key root@<OMNIBUS_IP>
    ```

1. Navigate to `http://localhost:9090` in a web browser to view the built-in Prometheus server.

1. To view the available metrics in Prometheus, navigate to `http://localhost:9090/metrics`.

    > To see a more detailed list of each metric, check out the [documentation](https://docs.gitlab.com/ee/administration/monitoring/prometheus/gitlab_metrics.html).

## Task B. Viewing Prometheus Metrics

> For this example, suppose you wanted to monitor HTTP requests sent into your GitLab instance. To achieve this, we can use some built in GitLab metrics.

1. Navigate to `http://localhost:9090`.

1. In the input beside the **magnifying glass** button, type `http_requests_total`.

1. Click the **Execute** button.

1. Click **Table** to view a table of all the results generated by the query.

    > You will likely see a variety of different HTTP requests in the results. Note that you can see the `job`, `instance`, `HTTP method` and `status` of each request.

1. Click **Graph** to view a graph of your data.

    > On the left hand side of the graph, you will see a **-** and **+** button. You can click these buttons to change the scale of the graph. Try adjusting the scale to see how it impacts your data.

## Task C. Alert Configurations

> Prometheus can be used to alert administrators based on specific metrics. GitLab comes with a set of predefined alerts for Prometheus.

1. Navigate to `http://localhost:9090`.

1. Click **Alerts** in the top menu.

    > Note that there are two sets of alert rules, one named GitLab and one named Node. The GitLab alerts correspond to platform issues such as a service being down, Postgres being down, or high queueing within services. A Node alert corresponds to the server GitLab is deployed on.

1. Note the file that contains the alerting rules. By default, the file is `/var/opt/gitlab/prometheus/rules/gitlab.rules`.

    > As an administrator, you can define custom rules inside this file to use for alerting. This will allow you to monitor your system for any potential issues.

## Task D. Common Performance Metrics

There are a variety of different metrics administrators can use to monitor the performance of their GitLab instances. Let's examine a few common queries you can use to monitor an instance.

1. Navigate to `http://localhost:9090`.

1. In the input beside the **magnifying glass** button, type the following query:

    ```text
    ((node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) or ((node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) / node_memory_MemTotal_bytes)) * 100
    ```

    > This query will show you the percentage of memory available on your instance.

1. Click the **Graph** tab to view the percentage of memory over time.

1. In the query input, delete your previous query and replace it with the following query:

    ```text
    1 - avg without (mode,cpu) (rate(node_cpu_seconds_total{mode="idle"}[5m]))
    ```

    > This query will show you the percentage of CPU used on your instance.

1. Click **Graph** to view the percent of CPU used over time.

    > For these metrics and many others, you may want to consider alerting for specific conditions. For example, you could alert for cases where the CPU usage exceeds 50% consistently, as it might indicate an issue.

## Task E. Install Grafana

Grafana provides you with a method of visualizing logs and metrics for your GitLab instance. Let's start by installing Grafana

1. SSH into your GitLab instance.

1. Pull the Grafana key to your instance using `wget -q -O - https://apt.grafana.com/gpg.key | gpg --dearmor > /etc/apt/keyrings/grafana.gpg`.

1. Add the repository to your package manager using `echo "deb [signed-by=/etc/apt/keyrings/grafana.gpg] https://apt.grafana.com stable main" | tee /etc/apt/sources.list.d/grafana.list`.

1. Update the apt repository: `sudo apt-get update`.

1. Install Grafana and its related components using `apt-get install loki promtail grafana`.

1. Start the Grafana server using `sudo systemctl start grafana-server`.

1. To verify that Grafana is running, navigate to `http://your-omnibus-ip:3000/login`. Your default username and password are `admin`.

## Task F. Configure Grafana to collect logs

Grafana provides you with useful tools for log collection and analysis. Let's see how Grafana can be configured to capture and display some of our GitLab log files.

1. SSH onto your GitLab instance.

1. Open the file `/etc/promtail/config.yml` in the text editor of your choice.

1. In this file, verify your server, positions, and clients:

    ```yml
    server:
    http_listen_port: 9080
    grpc_listen_port: 0

    positions:
    filename: /tmp/positions.yaml

    clients:
    - url: http://localhost:3100/loki/api/v1/push
    ```

1. Take note specifically of the `loki` URL and port. You will use this later.

1. Log collection configurations are set in the `scrape_configs` section of the configuration file. These configurations require the following values to be set:

    - `targets`: The location of the target log file, usually `localhost`.
    - `job`: A unique name for the log scraping job.
    - `__path__`: The location of the log files.

1. As an example, copy the following `scrape_configs` into your Grafana configuration file, replacing the existing `scrape_configs` file.

    ```yml
    scrape_configs:
    - job_name: nginx
    static_configs:
    - targets:
        - localhost
        labels:
        job: nginx
        __path__: /var/log/gitlab/nginx/*
    - job_name: workhorse
    static_configs:
    - targets:
        - localhost
        labels:
        job: workhorse
        __path__: /var/log/gitlab/gitlab-workhorse/*
    - job_name: rails
    static_configs:
    - targets:
        - localhost
        labels:
        job: rails
        __path__: /var/log/gitlab/gitlab-rails/production_json.log

    ```

    > This configuration adds three log files to Grafana: Nginx, Workhorse, and rails.

1. After adding this data, save the file. Restart `promtail` using `sudo systemctl restart promtail`. Validate that your service is running with `sudo systemctl status promtail`.

1. In any text editor, open the file `/etc/loki/config.yml`. Comment out or remove the last three lines related to `querier:`. Your final file will look like this:

    ```yml
    auth_enabled: false

    server:
    http_listen_port: 3100
    grpc_listen_port: 9096
    log_level: debug
    grpc_server_max_concurrent_streams: 1000

    common:
    instance_addr: 127.0.0.1
    path_prefix: /tmp/loki
    storage:
        filesystem:
        chunks_directory: /tmp/loki/chunks
        rules_directory: /tmp/loki/rules
    replication_factor: 1
    ring:
        kvstore:
        store: inmemory

    query_range:
    results_cache:
        cache:
        embedded_cache:
            enabled: true
            max_size_mb: 100

    limits_config:
    metric_aggregation_enabled: true

    schema_config:
    configs:
        - from: 2020-10-24
        store: tsdb
        object_store: filesystem
        schema: v13
        index:
            prefix: index_
            period: 24h

    pattern_ingester:
    enabled: true
    metric_aggregation:
        loki_address: localhost:3100

    ruler:
    alertmanager_url: http://localhost:9093

    frontend:
    encoding: protobuf

    #querier:
    #  engine:
    #    enable_multi_variant_queries: true
    ```

1. Save the file. Restart `loki` using `sudo systemctl restart loki`. Validate that your service is running with `sudo systemctl status loki`.

1. We also need our logs to be readable by promtail and loki. To do this, we will modify the permissions using the command: `chmod -R 755 /var/log/gitlab`.

1. With this complete, navigate to Grafana at `http://your-gitlab-ip:3000/login`.

1. Authenticate as your admin user.

1. In the left sidebar, select **Connections > Add new connection**.

1. Select **Loki**.

1. Select **Add new data source**.

1. In the **URL**, input `http://localhost:3100`.

1. Select **Save & Test**.

1. You should see the message **Data source successfully connected**.

## Task G. Analyze data with Grafana

1. Navigate to your Grafana instance.

1. In the left sidebar, select **Explore**.

1. Make sure **Loki** is selected in the dropdown beside **Outline**.

1. In the **Label filters** enter `job`.

1. In the value, enter **nginx**.

    > You can replace this with any job name defined in your configuration file if you wish.

1. Select **Run query** to see your results. Take some time here to review the logs and options for filtering logs in Grafana.

## Lab Guide Complete

You have completed this lab exercise. You can view the other [lab guides for this course](/handbook/customer-success/professional-services-engineering/education-services/ilt-labs/sysadminhandson).

## Suggestions?

If you wish to make a change to the lab, please submit your changes via Merge Request.
